export const metadata = {
  en: {
    date: "January 14, 2026",
    readTime: "7",
    title:
      "Antigravity vs Cursor vs Claude Code: The Battle for the Developer's Soul",
    subtitle: "Value propositions, hardware moats, and the road to 2027.",
  },
  fr: {
    date: "14 Janvier 2026",
    readTime: "7",
    title:
      "Antigravity vs Cursor vs Claude Code : La bataille pour l'âme du développeur",
    subtitle: "Propositions de valeur, douves matérielles et route vers 2027.",
  },
};

export const content = {
  en: (
    <>
      <p>
        It's 2026, and the "AI coding assistant" is no longer a novelty—it's the
        oxygen in the room. I've spent the last few weeks trialing the big
        three: <strong>Antigravity</strong>, <strong>Cursor</strong>, and{" "}
        <strong>Claude Code</strong> (both the CLI and the IDE integration). The
        verdict? They are all incredible. Seriously. If you told me three years
        ago I'd have tools this capable, I would have laughed.
      </p>

      <p>
        But "incredible" doesn't help me decide where to put my subscription
        money. The real question is:{" "}
        <em>How do they actually impact our work?</em>
      </p>

      <h2>The Value Proposition: Quantifying the Unquantifiable</h2>
      <p>
        We're past the point of "this one writes better boilterplate." Now we're
        in the realm of agentic behavior. Quantifying the value of these tools
        is tricky. Is it lines of code per hour? Bugs prevented? Or is it
        something softer, like "mental energy conserved"?
      </p>

      <p>
        To me, the differentiator is how they handle <strong>context</strong>{" "}
        and <strong>intent</strong>. Antigravity feels like it's
        pair-programming with a senior engineer who knows the whole codebase.
        Cursor is the speed demon, predicting my next move before I even make
        it. Claude Code offers this deep, thoughtful analysis that feels like a
        code review from a patient mentor.
      </p>

      <p className="highlight">
        The profound shift isn't in typing faster; it's in thinking bigger.
      </p>

      <h2>The Long-Term Angle: Google's Hardware Moat</h2>
      <p>
        Here's an angle I can't shake: <strong>Infrastructure</strong>. We often
        look at the software layer, but the models running these agents are
        hungry. They need compute. Massive, specialized, localized compute.
      </p>

      <p>
        This is where I think Google has a tremendous, almost unfair advantage.
        They own the hardware (TPUs) and the datacenters. They control the atoms
        that move the bits. In the long run, as models get larger and context
        windows effectively become infinite, the cost of inference will be the
        defining factor.
      </p>

      <p>
        If Google can run a model 10x larger for 10% of the cost because they
        own the vertical stack, does that make them the inevitable winner?
        Maybe. Does it mean we should ignore the others? Absolutely not.
        Innovation often comes from constraints, and the competition is fierce.
      </p>

      <h2>Excited for 2026</h2>
      <p>
        One thing is sure: I've tried all three, and the results are
        mind-blowing. We are standing at the precipice of a new era in software
        engineering. I am genuinely excited to see what the rest of 2026 brings.
        If the models improve this much in another year, we won't just be
        writing code; we'll be conducting symphonies of logic.
      </p>
    </>
  ),
  fr: (
    <>
      <p>
        Nous sommes en 2026, et l'assistant de code IA n'est plus une nouveauté,
        c'est l'oxygène de la pièce. J'ai passé les dernières semaines à tester
        les trois grands : <strong>Antigravity</strong>, <strong>Cursor</strong>{" "}
        et <strong>Claude Code</strong> (à la fois le CLI et l'intégration IDE).
        Le verdict ? Ils sont tous incroyables. Sérieusement. Si vous m'aviez
        dit il y a trois ans que j'aurais des outils aussi performants, j'aurais
        ri.
      </p>

      <p>
        Mais "incroyable" ne m'aide pas à décider où placer mon argent
        d'abonnement. La vraie question est :{" "}
        <em>Comment impactent-ils réellement notre travail ?</em>
      </p>

      <h2>La proposition de valeur : Quantifier l'inquantifiable</h2>
      <p>
        Nous avons dépassé le stade du "celui-ci écrit mieux le code répétitif".
        Nous sommes maintenant dans le domaine du comportement agentique.
        Quantifier la valeur de ces outils est délicat. S'agit-il de lignes de
        code par heure ? De bugs évités ? Ou est-ce quelque chose de plus
        immatériel, comme "l'économie d'énergie mentale" ?
      </p>

      <p>
        Pour moi, le facteur de différenciation réside dans la manière dont ils
        gèrent le <strong>contexte</strong> et <strong>l'intention</strong>.
        Antigravity donne l'impression de faire de la programmation en binôme
        avec un ingénieur senior qui connaît toute la base de code. Cursor est
        le démon de la vitesse, prédisant mon prochain mouvement avant même que
        je ne le fasse. Claude Code offre cette analyse profonde et réfléchie
        qui ressemble à une revue de code d'un mentor patient.
      </p>

      <p className="highlight">
        Le changement profond n'est pas d'écrire plus vite, mais de penser plus
        grand.
      </p>

      <h2>L'angle à long terme : La douve matérielle de Google</h2>
      <p>
        Voici un aspect dont je ne peux me défaire :{" "}
        <strong>L'infrastructure</strong>. Nous regardons souvent la couche
        logicielle, mais les modèles qui font tourner ces agents sont affamés.
        Ils ont besoin de calcul. Un calcul massif, spécialisé et localisé.
      </p>

      <p>
        C'est là que je pense que Google a un avantage considérable, presque
        injuste. Ils possèdent le matériel (TPU) et les centres de données. Ils
        contrôlent les atomes qui déplacent les bits. À long terme, alors que
        les modèles s'agrandissent et que les fenêtres de contexte deviennent
        effectivement infinies, le coût de l'inférence sera le facteur
        déterminant.
      </p>

      <p>
        Si Google peut faire tourner un modèle 10 fois plus grand pour 10 % du
        coût parce qu'ils possèdent la pile verticale, cela les rend-ils
        inévitables gagnants ? Peut-être. Cela signifie-t-il que nous devrions
        ignorer les autres ? Absolument pas. L'innovation vient souvent des
        contraintes, et la concurrence est féroce.
      </p>

      <h2>Enthousiaste pour 2026</h2>
      <p>
        Une chose est sûre : j'ai essayé les trois, et les résultats sont
        époustouflants. Nous sommes au bord d'une nouvelle ère dans l'ingénierie
        logicielle. Je suis sincèrement impatient de voir ce que la suite de
        2026 nous réserve. Si les modèles s'améliorent autant en une seule
        année, nous ne ferons plus qu'écrire du code ; nous dirigerons des
        symphonies de logique.
      </p>
    </>
  ),
};
